{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path as pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import (\n",
    "    Settings,\n",
    "    SimpleDirectoryReader,\n",
    "    VectorStoreIndex,\n",
    ")\n",
    "\n",
    "from llama_index.embeddings.google_genai import GoogleGenAIEmbedding\n",
    "from llama_index.llms.gemini import Gemini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dt/53bpx70s19ndyhz8nj3phw1h0000gn/T/ipykernel_2035/2229232881.py:1: DeprecationWarning: Call to deprecated class Gemini. (Should use `llama-index-llms-google-genai` instead, using Google's latest unified SDK. See: https://docs.llamaindex.ai/en/stable/examples/llm/google_genai/)\n",
      "  Settings.llm = Gemini(model=\"models/gemini-2.0-flash\")\n"
     ]
    }
   ],
   "source": [
    "Settings.llm = Gemini(model=\"models/gemini-2.0-flash\")\n",
    "Settings.embed_model = GoogleGenAIEmbedding(\n",
    "    model_name=\"text-embedding-004\",\n",
    "    embed_batch_size=100,\n",
    "    api_key=os.getenv(\"GOOGLE_API_KEY\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/Users/talentmatch/ai capstone/datasets/nfcorpus')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pt.cwd()\n",
    "\n",
    "data = pt.cwd() / 'datasets' / 'nfcorpus'\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.storage import StorageContext\n",
    "from llama_index.core.vector_stores import SimpleVectorStore\n",
    "\n",
    "documents = SimpleDirectoryReader(data).load_data()\n",
    "vector_store = SimpleVectorStore()\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "index = VectorStoreIndex.from_documents(documents, storage_context=storage_context)\n",
    "index.storage_context.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import load_index_from_storage\n",
    "\n",
    "storage_context = StorageContext.from_defaults(persist_dir=\"storage\")\n",
    "loaded_index = load_index_from_storage(storage_context)\n",
    "query_engine = loaded_index.as_query_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Assistant): Studies have shown that black tea, in the amounts studied, offered similar hydrating properties to water.\n",
      "\n",
      "(Assistant): Yes, the acid-base balance of food intake differs between vegetarians and non-vegetarians, with vegetarian diets resulting in more alkaline outcomes.\n",
      "\n",
      "(Assistant): Yes, dogs can be trained to identify bladder cancer in humans through urine odor with greater accuracy than random chance.\n",
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for *: 'NoneType' and 'float'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[40]\u001b[39m\u001b[32m, line 101\u001b[39m\n\u001b[32m     97\u001b[39m                 \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m     98\u001b[39m             \u001b[38;5;28mself\u001b[39m._get_response(question)\n\u001b[32m--> \u001b[39m\u001b[32m101\u001b[39m \u001b[43mMirascopeBot\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[40]\u001b[39m\u001b[32m, line 98\u001b[39m, in \u001b[36mMirascopeBot.run\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     96\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m question == \u001b[33m\"\u001b[39m\u001b[33mexit\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m     97\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m98\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquestion\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[40]\u001b[39m\u001b[32m, line 88\u001b[39m, in \u001b[36mMirascopeBot._get_response\u001b[39m\u001b[34m(self, question)\u001b[39m\n\u001b[32m     87\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_get_response\u001b[39m(\u001b[38;5;28mself\u001b[39m, question: \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m88\u001b[39m     context = \u001b[43mget_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquestion\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     89\u001b[39m     answer = \u001b[38;5;28mself\u001b[39m._step(context, question)\n\u001b[32m     90\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m(Assistant):\u001b[39m\u001b[33m\"\u001b[39m, answer.content)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[40]\u001b[39m\u001b[32m, line 64\u001b[39m, in \u001b[36mget_documents\u001b[39m\u001b[34m(query)\u001b[39m\n\u001b[32m     50\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"The get_documents tool that retrieves Mirascope documentation based on the\u001b[39;00m\n\u001b[32m     51\u001b[39m \u001b[33;03mrelevance of the query\"\"\"\u001b[39;00m\n\u001b[32m     52\u001b[39m query_engine = loaded_index.as_query_engine(\n\u001b[32m     53\u001b[39m     similarity_top_k=\u001b[32m10\u001b[39m,\n\u001b[32m     54\u001b[39m     node_postprocessors=[\n\u001b[32m   (...)\u001b[39m\u001b[32m     61\u001b[39m     response_mode=\u001b[33m\"\u001b[39m\u001b[33mtree_summarize\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     62\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m64\u001b[39m response = \u001b[43mquery_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     65\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response, Response):\n\u001b[32m     66\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m response.response \u001b[38;5;129;01mor\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mNo documents found.\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/capstone/lib/python3.13/site-packages/llama_index/core/instrumentation/dispatcher.py:322\u001b[39m, in \u001b[36mDispatcher.span.<locals>.wrapper\u001b[39m\u001b[34m(func, instance, args, kwargs)\u001b[39m\n\u001b[32m    319\u001b[39m             _logger.debug(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFailed to reset active_span_id: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    321\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m322\u001b[39m     result = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    323\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, asyncio.Future):\n\u001b[32m    324\u001b[39m         \u001b[38;5;66;03m# If the result is a Future, wrap it\u001b[39;00m\n\u001b[32m    325\u001b[39m         new_future = asyncio.ensure_future(result)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/capstone/lib/python3.13/site-packages/llama_index/core/base/base_query_engine.py:52\u001b[39m, in \u001b[36mBaseQueryEngine.query\u001b[39m\u001b[34m(self, str_or_query_bundle)\u001b[39m\n\u001b[32m     50\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(str_or_query_bundle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m     51\u001b[39m         str_or_query_bundle = QueryBundle(str_or_query_bundle)\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m     query_result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstr_or_query_bundle\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     53\u001b[39m dispatcher.event(\n\u001b[32m     54\u001b[39m     QueryEndEvent(query=str_or_query_bundle, response=query_result)\n\u001b[32m     55\u001b[39m )\n\u001b[32m     56\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m query_result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/capstone/lib/python3.13/site-packages/llama_index/core/instrumentation/dispatcher.py:322\u001b[39m, in \u001b[36mDispatcher.span.<locals>.wrapper\u001b[39m\u001b[34m(func, instance, args, kwargs)\u001b[39m\n\u001b[32m    319\u001b[39m             _logger.debug(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFailed to reset active_span_id: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    321\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m322\u001b[39m     result = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    323\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, asyncio.Future):\n\u001b[32m    324\u001b[39m         \u001b[38;5;66;03m# If the result is a Future, wrap it\u001b[39;00m\n\u001b[32m    325\u001b[39m         new_future = asyncio.ensure_future(result)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/capstone/lib/python3.13/site-packages/llama_index/core/query_engine/retriever_query_engine.py:178\u001b[39m, in \u001b[36mRetrieverQueryEngine._query\u001b[39m\u001b[34m(self, query_bundle)\u001b[39m\n\u001b[32m    174\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Answer a query.\"\"\"\u001b[39;00m\n\u001b[32m    175\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m.callback_manager.event(\n\u001b[32m    176\u001b[39m     CBEventType.QUERY, payload={EventPayload.QUERY_STR: query_bundle.query_str}\n\u001b[32m    177\u001b[39m ) \u001b[38;5;28;01mas\u001b[39;00m query_event:\n\u001b[32m--> \u001b[39m\u001b[32m178\u001b[39m     nodes = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_bundle\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    179\u001b[39m     response = \u001b[38;5;28mself\u001b[39m._response_synthesizer.synthesize(\n\u001b[32m    180\u001b[39m         query=query_bundle,\n\u001b[32m    181\u001b[39m         nodes=nodes,\n\u001b[32m    182\u001b[39m     )\n\u001b[32m    183\u001b[39m     query_event.on_end(payload={EventPayload.RESPONSE: response})\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/capstone/lib/python3.13/site-packages/llama_index/core/query_engine/retriever_query_engine.py:133\u001b[39m, in \u001b[36mRetrieverQueryEngine.retrieve\u001b[39m\u001b[34m(self, query_bundle)\u001b[39m\n\u001b[32m    132\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mretrieve\u001b[39m(\u001b[38;5;28mself\u001b[39m, query_bundle: QueryBundle) -> List[NodeWithScore]:\n\u001b[32m--> \u001b[39m\u001b[32m133\u001b[39m     nodes = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_retriever\u001b[49m\u001b[43m.\u001b[49m\u001b[43mretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_bundle\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    134\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._apply_node_postprocessors(nodes, query_bundle=query_bundle)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/capstone/lib/python3.13/site-packages/llama_index/core/instrumentation/dispatcher.py:322\u001b[39m, in \u001b[36mDispatcher.span.<locals>.wrapper\u001b[39m\u001b[34m(func, instance, args, kwargs)\u001b[39m\n\u001b[32m    319\u001b[39m             _logger.debug(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFailed to reset active_span_id: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    321\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m322\u001b[39m     result = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    323\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, asyncio.Future):\n\u001b[32m    324\u001b[39m         \u001b[38;5;66;03m# If the result is a Future, wrap it\u001b[39;00m\n\u001b[32m    325\u001b[39m         new_future = asyncio.ensure_future(result)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/capstone/lib/python3.13/site-packages/llama_index/core/base/base_retriever.py:245\u001b[39m, in \u001b[36mBaseRetriever.retrieve\u001b[39m\u001b[34m(self, str_or_query_bundle)\u001b[39m\n\u001b[32m    240\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m.callback_manager.as_trace(\u001b[33m\"\u001b[39m\u001b[33mquery\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    241\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m.callback_manager.event(\n\u001b[32m    242\u001b[39m         CBEventType.RETRIEVE,\n\u001b[32m    243\u001b[39m         payload={EventPayload.QUERY_STR: query_bundle.query_str},\n\u001b[32m    244\u001b[39m     ) \u001b[38;5;28;01mas\u001b[39;00m retrieve_event:\n\u001b[32m--> \u001b[39m\u001b[32m245\u001b[39m         nodes = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_retrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_bundle\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    246\u001b[39m         nodes = \u001b[38;5;28mself\u001b[39m._handle_recursive_retrieval(query_bundle, nodes)\n\u001b[32m    247\u001b[39m         retrieve_event.on_end(\n\u001b[32m    248\u001b[39m             payload={EventPayload.NODES: nodes},\n\u001b[32m    249\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/capstone/lib/python3.13/site-packages/llama_index/core/instrumentation/dispatcher.py:322\u001b[39m, in \u001b[36mDispatcher.span.<locals>.wrapper\u001b[39m\u001b[34m(func, instance, args, kwargs)\u001b[39m\n\u001b[32m    319\u001b[39m             _logger.debug(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFailed to reset active_span_id: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    321\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m322\u001b[39m     result = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    323\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, asyncio.Future):\n\u001b[32m    324\u001b[39m         \u001b[38;5;66;03m# If the result is a Future, wrap it\u001b[39;00m\n\u001b[32m    325\u001b[39m         new_future = asyncio.ensure_future(result)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/capstone/lib/python3.13/site-packages/llama_index/core/indices/vector_store/retrievers/retriever.py:103\u001b[39m, in \u001b[36mVectorIndexRetriever._retrieve\u001b[39m\u001b[34m(self, query_bundle)\u001b[39m\n\u001b[32m     97\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m query_bundle.embedding \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(query_bundle.embedding_strs) > \u001b[32m0\u001b[39m:\n\u001b[32m     98\u001b[39m         query_bundle.embedding = (\n\u001b[32m     99\u001b[39m             \u001b[38;5;28mself\u001b[39m._embed_model.get_agg_embedding_from_queries(\n\u001b[32m    100\u001b[39m                 query_bundle.embedding_strs\n\u001b[32m    101\u001b[39m             )\n\u001b[32m    102\u001b[39m         )\n\u001b[32m--> \u001b[39m\u001b[32m103\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_nodes_with_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_bundle\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/capstone/lib/python3.13/site-packages/llama_index/core/indices/vector_store/retrievers/retriever.py:180\u001b[39m, in \u001b[36mVectorIndexRetriever._get_nodes_with_embeddings\u001b[39m\u001b[34m(self, query_bundle_with_embeddings)\u001b[39m\n\u001b[32m    176\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_get_nodes_with_embeddings\u001b[39m(\n\u001b[32m    177\u001b[39m     \u001b[38;5;28mself\u001b[39m, query_bundle_with_embeddings: QueryBundle\n\u001b[32m    178\u001b[39m ) -> List[NodeWithScore]:\n\u001b[32m    179\u001b[39m     query = \u001b[38;5;28mself\u001b[39m._build_vector_store_query(query_bundle_with_embeddings)\n\u001b[32m--> \u001b[39m\u001b[32m180\u001b[39m     query_result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_vector_store\u001b[49m\u001b[43m.\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    181\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._build_node_list_from_query_result(query_result)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/capstone/lib/python3.13/site-packages/llama_index/core/vector_stores/simple.py:376\u001b[39m, in \u001b[36mSimpleVectorStore.query\u001b[39m\u001b[34m(self, query, **kwargs)\u001b[39m\n\u001b[32m    368\u001b[39m     top_similarities, top_ids = get_top_k_mmr_embeddings(\n\u001b[32m    369\u001b[39m         query_embedding,\n\u001b[32m    370\u001b[39m         embeddings,\n\u001b[32m   (...)\u001b[39m\u001b[32m    373\u001b[39m         mmr_threshold=mmr_threshold,\n\u001b[32m    374\u001b[39m     )\n\u001b[32m    375\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m query.mode == VectorStoreQueryMode.DEFAULT:\n\u001b[32m--> \u001b[39m\u001b[32m376\u001b[39m     top_similarities, top_ids = \u001b[43mget_top_k_embeddings\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    377\u001b[39m \u001b[43m        \u001b[49m\u001b[43mquery_embedding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    378\u001b[39m \u001b[43m        \u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    379\u001b[39m \u001b[43m        \u001b[49m\u001b[43msimilarity_top_k\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m.\u001b[49m\u001b[43msimilarity_top_k\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    380\u001b[39m \u001b[43m        \u001b[49m\u001b[43membedding_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnode_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    381\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    382\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    383\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mInvalid query mode: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquery.mode\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/capstone/lib/python3.13/site-packages/llama_index/core/indices/query/embedding_utils.py:30\u001b[39m, in \u001b[36mget_top_k_embeddings\u001b[39m\u001b[34m(query_embedding, embeddings, similarity_fn, similarity_top_k, embedding_ids, similarity_cutoff)\u001b[39m\n\u001b[32m     28\u001b[39m similarity_heap: List[Tuple[\u001b[38;5;28mfloat\u001b[39m, Any]] = []\n\u001b[32m     29\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, emb \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(embeddings_np):\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m     similarity = \u001b[43msimilarity_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_embedding_np\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43memb\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[32m     31\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m similarity_cutoff \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m similarity > similarity_cutoff:\n\u001b[32m     32\u001b[39m         heapq.heappush(similarity_heap, (similarity, embedding_ids[i]))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/capstone/lib/python3.13/site-packages/llama_index/core/base/embeddings/base.py:62\u001b[39m, in \u001b[36msimilarity\u001b[39m\u001b[34m(embedding1, embedding2, mode)\u001b[39m\n\u001b[32m     60\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m np.dot(embedding1, embedding2)\n\u001b[32m     61\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m62\u001b[39m     product = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43membedding1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     63\u001b[39m     norm = np.linalg.norm(embedding1) * np.linalg.norm(embedding2)\n\u001b[32m     64\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m product / norm\n",
      "\u001b[31mTypeError\u001b[39m: unsupported operand type(s) for *: 'NoneType' and 'float'"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "from llama_index.core.base.response.schema import Response\n",
    "from llama_index.core.postprocessor import LLMRerank\n",
    "from mirascope.core import google, prompt_template\n",
    "from pydantic import BaseModel\n",
    "\n",
    "\n",
    "\n",
    "def custom_parse_choice_select_answer_fn(\n",
    "    answer: str, num_choices: int, raise_error: bool = False\n",
    ") -> tuple[list[int], list[float]]:\n",
    "    \"\"\"Custom parse choice select answer function.\"\"\"\n",
    "    answer_lines = answer.split(\"\\n\")\n",
    "    answer_nums = []\n",
    "    answer_relevances = []\n",
    "    for answer_line in answer_lines:\n",
    "        line_tokens = answer_line.split(\",\")\n",
    "        if len(line_tokens) != 2:\n",
    "            if not raise_error:\n",
    "                continue\n",
    "            else:\n",
    "                raise ValueError(\n",
    "                    f\"Invalid answer line: {answer_line}. \"\n",
    "                    \"Answer line must be of the form: \"\n",
    "                    \"answer_num: , answer_relevance: \"\n",
    "                )\n",
    "        split_tokens = line_tokens[0].split(\":\")\n",
    "        if (\n",
    "            len(split_tokens) != 2\n",
    "            or split_tokens[1] is None\n",
    "            or not split_tokens[1].strip().isdigit()\n",
    "        ):\n",
    "            continue\n",
    "        answer_num = int(line_tokens[0].split(\":\")[1].strip())\n",
    "        if answer_num > num_choices:\n",
    "            continue\n",
    "        answer_nums.append(answer_num)\n",
    "        # extract just the first digits after the colon.\n",
    "        _answer_relevance = re.findall(r\"\\d+\", line_tokens[1].split(\":\")[1].strip())[0]\n",
    "        answer_relevances.append(float(_answer_relevance))\n",
    "    return answer_nums, answer_relevances\n",
    "\n",
    "\n",
    "def get_documents(query: str) -> str:\n",
    "    \"\"\"The get_documents tool that retrieves Mirascope documentation based on the\n",
    "    relevance of the query\"\"\"\n",
    "    query_engine = loaded_index.as_query_engine(\n",
    "        similarity_top_k=10,\n",
    "        node_postprocessors=[\n",
    "            LLMRerank(\n",
    "                choice_batch_size=5,\n",
    "                top_n=2,\n",
    "                parse_choice_select_answer_fn=custom_parse_choice_select_answer_fn,\n",
    "            )\n",
    "        ],\n",
    "        response_mode=\"tree_summarize\",\n",
    "    )\n",
    "\n",
    "    response = query_engine.query(query)\n",
    "    if isinstance(response, Response):\n",
    "        return response.response or \"No documents found.\"\n",
    "    return \"No documents found.\"\n",
    "\n",
    "\n",
    "class MirascopeBot(BaseModel):\n",
    "    @google.call(model=\"gemini-2.0-flash\")\n",
    "    @prompt_template(\n",
    "        \"\"\"\n",
    "        SYSTEM:\n",
    "        You are an AI Assistant that is an expert at answering questions about Mirascope.\n",
    "        Here is the relevant documentation to answer the question.\n",
    "\n",
    "        Context:\n",
    "        {context}\n",
    "\n",
    "        USER:\n",
    "        {question}\n",
    "        \"\"\"\n",
    "    )\n",
    "    def _step(self, context: str, question: str): ...\n",
    "\n",
    "    def _get_response(self, question: str):\n",
    "        context = get_documents(question)\n",
    "        answer = self._step(context, question)\n",
    "        print(\"(Assistant):\", answer.content)\n",
    "        return\n",
    "\n",
    "    def run(self):\n",
    "        while True:\n",
    "            question = input(\"(User): \")\n",
    "            if question == \"exit\":\n",
    "                break\n",
    "            self._get_response(question)\n",
    "\n",
    "\n",
    "MirascopeBot().run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capstone",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
